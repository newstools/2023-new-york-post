Mark-Zuckerberg-owned Facebook and Instagram scrambled to remove hundreds of video clips touting an app that creates AI-generated deepfake videos of Hollywood stars in sexually suggestive poses. One ad that circulated on social media shows a deepfake of “Harry Potter” heroine Emma Watson gazing sensually into the camera while kneeling to the floor just moments before it appears she is about to perform a sex act. The ad then displays the name of the app, FaceMega, which touts itself as a tool for creating “deepfake face swap videos.” FaceMega circulated more than 230 ads on Meta’s social media platforms using deepfake videos depicting the likenesses of Watson and “Avengers” star Scarlett Johansson, according to NBC News. “Replace face with anyone,” the captions on 80 of the ads read. “Enjoy yourself with AI swap face technology.” “Deepfake” is the term used to describe a video in which a person’s face is digitally altered with the aid of artificial intelligence to the point where they resemble somebody else — most often a celebrity or well-known person. The offending ads were spotted by Lauren Barton, a journalism student based in Tennessee. She tweeted the video clip featuring the Watson deepfake on her Twitter feed Monday. Meta, which owns Facebook and Instagram, sprang into action after the video went viral, having been viewed more than 16 million times, according to the Twitter view counter. “Our policies prohibit adult content regardless of whether it is generated by AI or not, and we have restricted this Page from advertising on our platform,” a spokesperson for Meta told The Post on Thursday. A spokesperson for Google told The Post that the company has removed the app from its Play Store. The Google spokesperson referred The Post to its policies regulating “inappropriate content,” including “sexual content and profanity.” “We don’t allow apps that contain or promote sexual content or profanity, including pornography, or any content or services intended to be sexually gratifying,” according to the Play Store terms of service. “We don’t allow apps or app content that appear to promote a sexual act in exchange for compensation.” An Apple spokesperson declined to comment, though a source within the company told The Post that the app has been removed from the App Store. Privacy advocates have grown alarmed at potential abuses of deepfake technology, particularly the practice of superimposing women’s likenesses into pornographic images to make it appear that they were willing participants. Last month, Sweet Anita, a 32-year-old British social media star, discovered that her face had been digitally pasted onto the body of a woman who was filmed in pornographic videos. It’s not just sex videos that pose a danger. Last year, social media platforms removed a deepfake video showing Ukrainian President Volodymyr Zelensky telling his countrymen to surrender to Russia.